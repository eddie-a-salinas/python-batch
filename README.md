# Python-Batch

Example python/bash scripts as a capability exercise/demonstration.  Notes and comments about their composition and alternative strategies are also below.

### Quick-Start

Example usage and output

```
$ ./summer_usage.sh 
78b90162e0974a87f47e458013ccd816  -
78b90162e0974a87f47e458013ccd816  -
The md5sum hashes match, so the output files are equivalent.
The grand total is 164804494 !
```

### Quick-Start (Docker)

Example usage this time with docker.

```
$ docker run -v ${PWD}:/work --rm -it  python:3.8.5   /bin/bash -c 'cd /work && ./summer_usage.sh'
78b90162e0974a87f47e458013ccd816  -
78b90162e0974a87f47e458013ccd816  -
The md5sum hashes match, so the output files are equivalent.
The grand total is 164804494 !
```

## Notes on Scripts and Their Implementation

The python script reads a file of integers, computes the sum, and writes the sum to an output file.

```
$ ./summer.py -h
usage: summer.py [-h] IN_FILE OUT_FILE

read a file of integers, \compute the sum, and write the sum to an output file

positional arguments:
  IN_FILE     input file of integers
  OUT_FILE    output file of sum of integers

optional arguments:
  -h, --help  show this help message and exit

```

I'd like to point out that the script uses command-line arguments.  This is in contrast to scripts whose usage requires their editing.  For example, a script might have input or output hard coded, and they'd need to be edited before being invoked on other data files not hard-coded in the script.  In this repo/example no such things are hard coded, and input and output are given on a command-line.  I appreciate the use of such arguments which allow the script to be used more like a tool and in a more modular fashion.  The summer_usage.sh is an example of such modular usage.

The bash script "summer_usage.sh" uses example data in the data_files directory to exercise summer.py.  The script is run on all the data files in two ways.

1.  the files are run in a bash for loop
2.  the files are run in a bash "one-liner" using "find" and "xargs".

After running the script on the data files in each of the two ways, an md5sum hash of the outputs is computed.  The matching of the hashes verifies that the two ways (for loop and find+xargs) are equivalent.  Between the two runs, the \*.sum.txt files are deleted two assure they are removed between runs to make the comparision more valid.

Each .dat input file in the data_files directory has its sum stored in the corresponding .sum.txt file.  After each of the .sum.txt files is generated they are all considered and a "grand total" is computed and shown.  the grand total is also itself generated by the summer.py script but via a bash one-liner with streaming/pipes.  Here the one-liner style highlights how the command-line arguments help enable the script usable in a modular fashion.

```
$ head --verbose --lines=100 summer_usage.sh 
==> summer_usage.sh <==
#!/bin/bash

#iterate over data files and write output
for D in `find data_files/*.dat`; do
    python3 summer.py ${D} ${D}.sum.txt
    done ;
#observe the hash of output
cat data_files/*.sum.txt|md5sum
#delete output
rm -f  data_files/*.sum.txt

#repeat but using xargs (here "{}" is like x in f(x) )
find data_files/data.*.dat | xargs -I {} python3 summer.py {} {}.sum.txt
cat data_files/*.sum.txt|md5sum

echo "The md5sum hashes match, so the output files are equivalent." ; 

#now compute a grand total
cat data_files/*.sum.txt | python3 summer.py /dev/stdin /dev/stdout > grand_total.txt
GRAND_TOTAL=`cat grand_total.txt`;
echo "The grand total is ${GRAND_TOTAL} !" ; 
```


## Other Notes & Thoughts

I support and appreciate the usage of command-line arguments in python scripts to enable them to be used modularly which may also help to scale analyses.  In addition, effective usage of command-line arguments gives an opportunity to write "help" text on the usage of the script and how to call it (as seen above under the output of ".summer.py -h").

The summer.py could have been executed by the GNU "parallel" program which can take a list of commands and run them in parallel.

There are other ways to invoke summer.py too - perhaps via "system" calls in ptyhon, perl, or another language.  

When deciding how to do something or how to write code some things to consider include:
1.  readability
2.  debuggability
3.  maintainability
4.  speed/effectiveness of a particular implementation

Something I often consider is that unless one implementation is "significantly" faster or allows much more "modularity" than alternatives, generally code something in the way that optimizes for readability, maintainability, and debuggability.  It's not a hard rule though.





















